install.packages("e1071")
library(iml)
library(future)
library(future.callr)
library(e1071)
set.seed(175)
system.time(SupportVectorMachine <- svm(
y= Dfm_Training@docvars$sentiment,
x=Matrice_Training, kernel='linear', cost = 1))
length(SupportVectorMachine$index)
system.time(Test_predictedSV <- predict(SupportVectorMachine,
Matrice_Test))
Test_predictedSV
View(Test_data)
Test_data$Bayes <- Test_predictedNB
View(Test_data)
Test_data$Forest <- RF$predicted
Test_data$Support <- Test_predictedSV
View(Test_data)
View(Campione)
results <- as.data.frame(rbind(prop.table(table(Test_predictedNB)),
prop.table(table(Test_predictedRF)),
prop.table(table(Test_predictedSV))))
RF
RF
table(Campione$sentiment)
(6+17+10+17+4+2)/200
plot(RF, type = "l", col = c("black", "steelblue4","violetred4", "springgreen4"),
main = "Random Forest Model Errors: sentiment variable")
plot(RF, type = "l", col = c("black", "steelblue4","violetred4", "springgreen4"),
main = "Random Forest Model Errors: sentiment variable")
legend("topright", horiz = F, cex = 0.7,
fill = c("springgreen4", "black", "steelblue4", "violetred4"),
c("Positive error", "Average error", "Negative error", "Neutral error"))
Errori <- as.data.frame(RF$err.rate)
which.min(Errori$OOB) # 96
set.seed(150)
system.time(RF <- randomForest(y= Dfm_Training@docvars$sentiment,
x= Matrice_Training,
importance=TRUE,
do.trace=FALSE,
ntree=53))
RF
plot(RF, type = "l", col = c("black", "steelblue4","violetred4", "springgreen4"),
main = "Random Forest Model Errors: sentiment variable")
legend("topright", horiz = F, cex = 0.7,
fill = c("springgreen4", "black", "steelblue4", "violetred4"),
c("Positive error", "Average error", "Negative error", "Neutral error"))
system.time(Test_predictedRF <- predict(RF,
Matrice_Test ,type="class"))
Test_data$Forest <- Test_predictedRF
View(Test_data)
results <- as.data.frame(rbind(prop.table(table(Test_predictedNB)),
prop.table(table(Test_predictedRF)),
prop.table(table(Test_predictedSV))))
View(results)
library(reshape2)
# 1: Pulizia e Preparazione dei dati ----
install.packages("reshape2")
library(reshape2)
results$algorithm <- c("Naive Bayes", "Random Forest", "Support Vector Machine")
df.long<-melt(results,id.vars=c("algorithm"))
View(df.long)
ggplot(df.long,aes(algorithm,value,fill=variable))+
geom_bar(position="dodge",stat="identity") + scale_fill_manual(values = c("violetred3", "yellow3", "orange2")) +
labs(title = "Comparazione delle predizioni") +
theme(axis.text.x = element_text(color="#993333", angle=90)) + coord_flip() +
ylab(label="Proporzione delle categorie nel test set") + xlab("Algoritmi") +
guides(fill=guide_legend(title="Categorie di \nsentiment")) +
theme(plot.title = element_text(color = "black", size = 12, face = "plain"),
axis.title=element_text(size=11,face="plain"),
axis.text= element_text(size =10, face = "italic")
)
ggplot(df.long,aes(algorithm,value,fill=variable))+
geom_bar(position="dodge",stat="identity") + scale_fill_manual(values = c("violetred3", "yellow3", "orange2")) +
labs(title = "Comparazione delle predizioni") +
theme(axis.text.x = element_text(color="#993333", angle=90)) + coord_flip() +
ylab(label="Proporzione delle categorie nel test set") + xlab("Algoritmi") +
guides(fill=guide_legend(title="Categorie di \nsentiment")) +
theme(plot.title = element_text(color = "black", size = 12, face = "plain"),
axis.title=element_text(size=11,face="plain"),
axis.text= element_text(size =10, face = "italic")
)
summary(NaiveBayesModel)
# 1: Pulizia e Preparazione dei dati ----
install.packages(cvTools)
# 1: Pulizia e Preparazione dei dati ----
install.packages("cvTools")
install.packages("caret")
library(caret)
library(cvTools)
install.packages("robustbase")
install.packages("robustbase")
Matrice_Training2 <- Matrice_Training
set.seed(200)
#Definiamo un oggetto k che indichi il numero di folders
k <- 5
#Dividiamo la matrice in k folders
folds <- cvFolds(NROW(Matrice_Training2), K = k)
system.time(for(i in 1:k){
Matrice_Training <-
Matrice_Training2 [folds$subsets[folds$which != i], ]
ValidationSet <-
Matrice_Training2 [folds$subsets[folds$which == i], ]
set.seed(200)
NaiveBayesModel <- multinomial_naive_bayes(
y= Dfm_Training[folds$subsets[folds$which != i], ]
@docvars$sentiment ,
x=Matrice_Training, laplace = 1)
Predictions_NB <- predict(NaiveBayesModel,
newdata = ValidationSet,
type = "class")
class_table <- table("Predictions"= Predictions_NB,
"Actual"=Dfm_Training[folds$subsets[folds$which == i], ]@docvars$sentiment)
print(class_table)
df<-confusionMatrix( class_table, mode = "everything")
df_measures_NB<-paste0("conf.mat.nb",i)
assign(df_measures_NB,df)
})
NB_Prediction <- data.frame(col1=vector(), col2=vector(), col3=vector(), col4=vector())
for(i in mget(ls(pattern = "conf.mat.nb")) ) {
Accuracy <-(i)$overall[1]
p <- as.data.frame((i)$byClass)
F1_negative <- p$F1[1]
F1_neutral <- p$F1[2]
F1_positive <- p$F1[3]
NB_Prediction <- rbind(NB_Prediction , cbind(Accuracy , F1_negative ,
F1_neutral, F1_positive ))
}
#guardiamo la struttura
str(NB_Prediction)
NB_Prediction [is.na(NB_Prediction )] <- 0
#guardiamo la struttura
str(NB_Prediction)
AverageAccuracy_NB <- mean(NB_Prediction[, 1] )
AverageF1_NB<- mean(colMeans(NB_Prediction[-1] ))
AverageAccuracy_NB
AverageF1_NB
system.time(for(i in 1:k){
Matrice_Training <-
Matrice_Training2 [folds$subsets[folds$which != i], ]
ValidationSet <-
Matrice_Training2 [folds$subsets[folds$which == i], ]
set.seed(250)
RandomForest <- randomForest(
y= Dfm_Training[folds$subsets[folds$which != i], ]
@docvars$sentiment ,
x=Matrice_Training, do.trace=FALSE, ntree=53)
Predictions_RF <- predict(RandomForest,
newdata= ValidationSet,
type="class")
class_table <- table("Predictions"= Predictions_RF,
"Actual"=Dfm_Training[folds$subsets[folds$which == i], ]@docvars$sentiment)
print(class_table)
df<-confusionMatrix( class_table, mode = "everything")
df_measures_RF<-paste0("conf.mat.rf",i)
assign(df_measures_RF,df)
})
RF_Predictions <- data.frame(col1=vector(), col2=vector(), col3=vector(), col4 = vector())
for(i in mget(ls(pattern = "conf.mat.rf")) ) {
Accuracy <-(i)$overall[1]
p <- as.data.frame((i)$byClass)
F1_negative <- p$F1[1]
F1_neutral <- p$F1[2]
F1_positive <- p$F1[3]
RF_Predictions <- rbind(RF_Predictions , cbind(Accuracy , F1_negative ,
F1_neutral, F1_positive ))
}
str(RF_Predictions)
RF_Predictions [is.na(RF_Predictions )] <- 0
#Calcoliamo i valori medi
AverageAccuracy_RF <- mean(RF_Predictions[, 1] )
AverageF1_RF<- mean(colMeans(RF_Predictions[-1] ))
AverageAccuracy_RF
AverageF1_RF
system.time(for(i in 1:k){
Matrice_Training <-
Matrice_Training2 [folds$subsets[folds$which != i], ]
ValidationSet <-
Matrice_Training2 [folds$subsets[folds$which == i], ]
set.seed(300)
SupportVectorMachine<- svm(
y= Dfm_Training[folds$subsets[folds$which != i], ]
@docvars$sentiment,
x=Matrice_Training, kernel='linear', cost = 1)
Prediction_SVM <- predict(SupportVectorMachine,
newdata=ValidationSet)
class_table <- table("Predictions"= Prediction_SVM,
"Actual"=Dfm_Training[folds$subsets[folds$which == i], ]@docvars$sentiment)
print(class_table)
df<-confusionMatrix( class_table, mode = "everything")
df_measures_SVM<-paste0("conf.mat.sv",i)
assign(df_measures_SVM,df)
})
#Riempiamo il dataframe
for(i in mget(ls(pattern = "conf.mat.sv")) ) {
Accuracy <-(i)$overall[1]
p <- as.data.frame((i)$byClass)
F1_negative <- p$F1[1]
F1_neutral <- p$F1[2]
F1_positive <- p$F1[3]
SVM_Prediction <- rbind(SVM_Prediction , cbind(Accuracy , F1_negative ,
F1_neutral, F1_positive ))
}
SVM_Prediction <- data.frame(col1=vector(), col2=vector(), col3=vector(), col4=vector())
#Riempiamo il dataframe
for(i in mget(ls(pattern = "conf.mat.sv")) ) {
Accuracy <-(i)$overall[1]
p <- as.data.frame((i)$byClass)
F1_negative <- p$F1[1]
F1_neutral <- p$F1[2]
F1_positive <- p$F1[3]
SVM_Prediction <- rbind(SVM_Prediction , cbind(Accuracy , F1_negative ,
F1_neutral, F1_positive ))
}
str(SVM_Prediction)
SVM_Prediction [is.na(SVM_Prediction)] <- 0
#Calcoliamo i valori medi
AverageAccuracy_SVM <- mean(SVM_Prediction[, 1] )
AverageF1_SVM<- mean(colMeans(SVM_Prediction[-1] ))
AverageAccuracy_SVM
AverageF1_SVM
AccNB <- as.data.frame(AverageAccuracy_NB )
colnames(AccNB)[1] <- "NB"
#Creo un dataframe per RF
AccRF <- as.data.frame(AverageAccuracy_RF )
#Rinomino la colonna
colnames(AccRF)[1] <- "RF"
#Creo un dataframe per SVM
AccSVM<- as.data.frame(AverageAccuracy_SVM )
#Rinomino la colonna
colnames(AccSVM)[1] <- "SVM"
#Unisco in un unico dataframe i valori di accuracy dei tre modelli
Accuracy_models <- cbind(AccNB, AccRF, AccSVM)
Accuracy_models
Accuracy_models_Melt <-melt(Accuracy_models)
str(Accuracy_models_Melt)
Accuracy_models_Melt <-melt(Accuracy_models)
View(Accuracy_models_Melt)
View(df.long)
Accuracy_models_Melt <-melt(Accuracy_models, id.vars = c("variable"))
Accuracy_models_Melt <-melt(Accuracy_models, id.vars = "variable")
Accuracy_models_Melt <-melt(Accuracy_models)
str(Accuracy_models_Melt)
plot_accuracy <- ggplot(Accuracy_models_Melt, aes(x=variable, y=value, color = variable)) +
geom_boxplot() + xlab("Algorithm") + ylab(label="Values of accuracy") +
labs(title = "Cross-validation with k =5: values of accuracy") + coord_flip() +
theme_bw() +
guides(color=guide_legend(title="Algorithms")) +
theme(plot.title = element_text(color = "black", size = 12, face = "italic"),
axis.title.x =element_text(size=12,face="bold"),
axis.title.y =element_text(size=12, face = "plain"),
axis.text= element_text(size =10, face = "italic")
)
plot_accuracy
F1NB <- as.data.frame(AverageF1_NB)
colnames(F1NB)[1] <- "NB"
#RF
F1RF<- as.data.frame(AverageF1_RF )
colnames(F1RF)[1] <- "RF"
#SVM
F1SVM <- as.data.frame(AverageF1_SVM)
colnames(F1SVM)[1] <- "SVM"
#DATAFRAME
f1_models <- cbind(F1NB, F1RF, F1SVM)
f1_models
f1_models_melt <-melt(f1_models)
str(f1_models_melt)
plot_f1 <- ggplot(f1_models_melt, aes(x=variable, y=value, color = variable)) +
geom_boxplot() + xlab("Algorithm") + ylab(label="Values of f1") +
labs(title = "Cross-validation with k =5: values of f1") + coord_flip() +
theme_bw() +
guides(color=guide_legend(title="Algorithms")) +
theme(plot.title = element_text(color = "black", size = 12, face = "italic"),
axis.title.x =element_text(size=12,face="bold"),
axis.title.y =element_text(size=12, face = "plain"),
axis.text= element_text(size =10, face = "italic")
)
# 1: Pulizia e Preparazione dei dati ----
install.packages("gridExtra")
library(gridExtra)
grid.arrange(plot_accuracy, plot_f1, nrow=2)
View(Test_data)
View(Ita_StoresReview)
# Top parole del DFM
topfeatures(Dfm_Totale,100)
# Top parole del DFM
topfeatures(Dfm_Totale,300)
View(StoresReview)
# 1: Pulizia e Preparazione dei dati ----
library(readxl)
library(writexl)
library(rstudioapi)
library(quanteda)
library(quanteda.textstats)
library(naivebayes)
library(randomForest)
library(iml)
library(future)
library(future.callr)
library(e1071)
library(reshape2)
library(cvTools)
library(caret)
library(ggplot2)
library(gridExtra)
# Directory della cartella condivisa
setwd(dirname(getActiveDocumentContext()$path))
# Dataset
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Aggiunta Primary key
StoresReview$ID <- seq(1:nrow(StoresReview))
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[(StoresReview$lang_value == "it" |
is.na(StoresReview$lang_value) == TRUE) &
is.na(StoresReview$text) == FALSE,]
# Corpus con i testi NON vuoti
Corpus_Totale <- corpus(Ita_StoresReview)
# Frequenze delle caratteristiche del Corpus
apply(textstat_summary(Corpus_Totale)[,2:11], 2, sum)
# DFM... MODIFICARE LE CONDIZIONI TRIMMING
Dfm_Totale <- dfm(tokens(Corpus_Totale,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian")) %>%
dfm_trim(min_termfreq = 10,
min_docfreq = 2) # modificare le condizioni
# Lunghezza del DFM
summary(Dfm_Totale)
# Top parole del DFM
topfeatures(Dfm_Totale,300)
dfm(Corpus_Totale, select = "#*")
help(dfm)
dfm[, grepl("#", colnames(dfm))]
Dfm_Totale
colnames(Dfm_Totale)
colnames(Dfm_Totale)[grep("^#", colnames(Dfm_Totale))]
colnames(Dfm_Totale)[startsWith(...,"#")]
help("startswith")
help("startsWith")
startsWith(colnames(Dfm_Totale),"#")
colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),"#")]
colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),"@")]
Parole_Brutte <- c(colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),"#")],
colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),"@")])
Parole_Brutte
colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),c("#","@"))]
colnames(Dfm_Totale)[startsWith(trimws(colnames(Dfm_Totale),c("#","@")))]
colnames(Dfm_Totale)[startsWith(trimws(colnames(Dfm_Totale), c("#", "@")))]
colnames(Dfm_Totale)[grepl("^\\s*[#@]", trimws(colnames(Dfm_Totale)))]
colnames(Dfm_Totale)[grepl("^s*[#@]", trimws(colnames(Dfm_Totale)))]
colnames(Dfm_Totale)[grepl("^[#@]", trimws(colnames(Dfm_Totale)))]
colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),"^\\s*[#@]")]
colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),"^[#@]")]
colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),"^s*[#@]")]
colnames(Dfm_Totale)[grepl("^\\s*[#@]", trimws(colnames(Dfm_Totale)))]
Parole_Brutte <- colnames(Dfm_Totale)[grepl("^\\s*[#@]", trimws(colnames(Dfm_Totale)))]
Parole_Brutte <- c(colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),"#")],
colnames(Dfm_Totale)[startsWith(colnames(Dfm_Totale),"@")])
colnames(Dfm_Totale)[grepl("^\\s*[#@]", trimws(colnames(Dfm_Totale)))]
Parole_Brutte
sort(Parole_Brutte) == sort(colnames(Dfm_Totale)[grepl("^\\s*[#@]", trimws(colnames(Dfm_Totale)))])
Parole_Brutte <- colnames(Dfm_Totale)[grepl("^\\s*[#@]", trimws(colnames(Dfm_Totale)))]
Dfm_Totale <- Dfm_Totale[,!(colnames(Dfm_Totale) %in% Parole_Brutte)]
# Top parole del DFM
topfeatures(Dfm_Totale,300)
Parole_Popolari <- textstat_frequency(Dfm_Totale, n =20)
View(Parole_Popolari)
# DFM... MODIFICARE LE CONDIZIONI TRIMMING
Dfm_Totale <- dfm(tokens(Corpus_Totale,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian")) %>%
dfm_trim(min_termfreq = 10,
max_termfreq = 500,
min_docfreq = 2)
# Toglie i tag e gli hashtag
Parole_Brutte <- colnames(Dfm_Totale)[grepl("^\\s*[#@]", trimws(colnames(Dfm_Totale)))]
Dfm_Totale <- Dfm_Totale[,!(colnames(Dfm_Totale) %in% Parole_Brutte)]
Parole_Popolari <- textstat_frequency(Dfm_Totale, n =20)
View(Parole_Popolari)
ggplot(TopFeatures, aes(x=frequency, y=feature)) +
geom_point(size = 1.5, color = "Darkorange2") +
theme_bw() +
theme(axis.text.x = element_text(angle=360, hjust=1)) +
labs(x = "Features", y = "Frequenza",
title = "Le 20 parole più frequenti nei tweet sulla campagna #OpenToMeraviglia") +
theme(plot.title = element_text(color = "Darkorange2", size = 11, face = "bold"),
plot.subtitle = element_text(color = "black", size = 11, face = "italic" ))
ggplot(Parole_Popolari, aes(x=frequency, y=feature)) +
geom_point(size = 1.5, color = "Darkorange2") +
theme_bw() +
theme(axis.text.x = element_text(angle=360, hjust=1)) +
labs(x = "Features", y = "Frequenza",
title = "Le 20 parole più frequenti nelle recensioni") +
theme(plot.title = element_text(color = "Darkorange2", size = 11, face = "bold"),
plot.subtitle = element_text(color = "black", size = 11, face = "italic" ))
Parole_Popolari$feature <- with(Parole_Popolari, reorder(feature, frequency))
ggplot(Parole_Popolari, aes(x=frequency, y=feature)) +
geom_point(size = 1.5, color = "Darkorange2") +
theme_bw() +
theme(axis.text.x = element_text(angle=360, hjust=1)) +
labs(x = "Features", y = "Frequenza",
title = "Le 20 parole più frequenti nelle recensioni") +
theme(plot.title = element_text(color = "Darkorange2", size = 11, face = "bold"),
plot.subtitle = element_text(color = "black", size = 11, face = "italic" ))
textplot_wordcloud(OpenToMeraviglia_dfm_Trim,
min_size = 1.5,   #dimensione minima delle parole
max_size = 4,     #dimensione max
min.count = 10,    #inserisci una parola presente almeno n volte
max_words = 50,  #numero massimo di parole da visualizzare
random.order = FALSE,  #visualizzate in ordine di frequenza, se TRUE
#la grandezza delle parole verrà attribuita casualmente
random_color = FALSE,  #se FALSE i colori sono gli stessi per parole dello stesso "livello di importanza"
rotation = 0,    #rotazione delle parole
colors = RColorBrewer::brewer.pal(8,"Dark2"))
textplot_wordcloud(Dfm_Totale,
min_size = 1.5,   #dimensione minima delle parole
max_size = 4,     #dimensione max
min.count = 10,    #inserisci una parola presente almeno n volte
max_words = 50,  #numero massimo di parole da visualizzare
random.order = FALSE,  #visualizzate in ordine di frequenza, se TRUE
#la grandezza delle parole verrà attribuita casualmente
random_color = FALSE,  #se FALSE i colori sono gli stessi per parole dello stesso "livello di importanza"
rotation = 0,    #rotazione delle parole
colors = RColorBrewer::brewer.pal(8,"Dark2"))
# 1: Pulizia e Preparazione dei dati ----
install.packages("tm")
library(tm)
textplot_wordcloud(Dfm_Totale,
min_size = 1.5,   #dimensione minima delle parole
max_size = 4,     #dimensione max
min.count = 10,    #inserisci una parola presente almeno n volte
max_words = 50,  #numero massimo di parole da visualizzare
random.order = FALSE,  #visualizzate in ordine di frequenza, se TRUE
#la grandezza delle parole verrà attribuita casualmente
random_color = FALSE,  #se FALSE i colori sono gli stessi per parole dello stesso "livello di importanza"
rotation = 0,    #rotazione delle parole
colors = RColorBrewer::brewer.pal(8,"Dark2"))
textplot_wordcloud(Dfm_Totale,
min_size = 1.5,   #dimensione minima delle parole
max_size = 4,     #dimensione max
min.count = 10,    #inserisci una parola presente almeno n volte
max_words = 50,  #numero massimo di parole da visualizzare
random.order = FALSE,  #visualizzate in ordine di frequenza, se TRUE
#la grandezza delle parole verrà attribuita casualmente
random_color = FALSE,  #se FALSE i colori sono gli stessi per parole dello stesso "livello di importanza"
rotation = 0,    #rotazione delle parole
colors = RColorBrewer::brewer.pal(8,"Dark2"))
library(tm)
textplot_wordcloud(Dfm_Totale,
min_size = 1.5,   #dimensione minima delle parole
max_size = 4,     #dimensione max
min.count = 10,    #inserisci una parola presente almeno n volte
max_words = 50,  #numero massimo di parole da visualizzare
random.order = FALSE,  #visualizzate in ordine di frequenza, se TRUE
#la grandezza delle parole verrà attribuita casualmente
random_color = FALSE,  #se FALSE i colori sono gli stessi per parole dello stesso "livello di importanza"
rotation = 0,    #rotazione delle parole
colors = RColorBrewer::brewer.pal(8,"Dark2"))
col <- sapply(seq(0.4, 1, 0.3), function(x) adjustcolor("#F27349", x))
textplot_wordcloud(Dfm_Totale,
min_size = 1.5,
max_size = 4,
min.count = 10,
max_words = 50,
random.order = FALSE,
random_color = FALSE,
rotation = 0,
colors = col)
# 1: Pulizia e Preparazione dei dati ----
install.packages("wordcloud")
library(wordcloud)
# Top parole del DFM
topfeatures(Dfm_Totale,300)
textplot_wordcloud(Dfm_Totale,
min_size = 1.5,
max_size = 4,
min.count = 10,
max_words = 50,
random.order = FALSE,
random_color = FALSE,
rotation = 0,
colors = RColorBrewer::brewer.pal(8,"Dark2"))
wordcloud(colnames(Dfm_Totale),
min.freq = 10,
random.order = FALSE,
random.color = FALSE,
colors = RColorBrewer::brewer.pal(8,"Dark2"),
max.words = 50)
wordcloud(colnames(Dfm_Totale),
min.freq = 10,
random.order = FALSE,
random.color = FALSE,
max.words = 50)
warnings()
Matrice_Training
help(multinomial_naive_bayes)
help("multinomial_naive_bayes")
summary(NaiveBayesModel)
summary(NaiveBayesModel)
Matrice_Training
View(Places_ita)
View(Test_data)
