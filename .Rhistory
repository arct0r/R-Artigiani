min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
View(Tweet_ita)
apply(Tweet_ita, 2, function(x) sum(is.na(x)))
apply(Places_ita, 2, function(x) sum(is.na(x)))
Places_ita <- Places_ita[is.na(Places_ita$text) == TRUE,]
apply(Places_ita, 2, function(x) sum(is.na(x)))
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
Places_ita <- Places_ita[is.na(Places_ita$text) == FALSE,]
apply(Places_ita, 2, function(x) sum(is.na(x)))
set.seed(001)
Training_places <- sample(Places_ita, size = 160, replace = FALSE)
Training_tweet <- sample(Tweet_Stores$text, size = 40, replace = FALSE)
Training_tweet <- sample(Tweet_ita, size = 40, replace = FALSE)
View(Places_ita)
Training_places <- sample(Places_ita$text, size = 160, replace = FALSE)
Training_places
# librerie e dataset ----
library(readxl)
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
View(Ita_StoresReview)
StoresReview$ID <- seq(1:nrow(StoresReview))
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
Tweet_ita <- Ita_StoresReview[Ita_StoresReview$social == "twitter",]
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
apply(Tweet_ita, 2, function(x) sum(is.na(x)))
apply(Places_ita, 2, function(x) sum(is.na(x)))
Places_ita <- Places_ita[is.na(Places_ita$text) == FALSE,]
Prova <- corpus(Tweet_ita)
dimnames(Prova)
names(Prova)
View(Tweet_ita)
names(Prova) <- Tweet_ita$ID
names(Prova)
Prova
rm(Prova)
#Campionamento per il TRAINING STAGE
Tweet_Corpus <- corpus(Tweet_ita)
names(Tweet_Corpus) <- Tweet_ita$ID
Places_Corpus <- corpus(Places_ita)
names(Places_Corpus) <- Places_ita$ID
# librerie e dataset ----
library(readxl)
library(writexl)
library(rstudioapi)
library(quanteda)
library(quanteda.textstats)
library(ggplot2)
setwd(dirname(getActiveDocumentContext()$path))
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
StoresReview$ID <- seq(1:nrow(StoresReview))
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# Creazione del Corpus prendendo solo i testi NON vuoti
Corpus_Totale <- corpus(na.omit(Ita_StoresReview$text))
# NON PULISCE TUTTO. !!, emoji
Dfm_Totale <- dfm(tokens(Corpus_Totale,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING: condizioni TEMPORANEE.
Dfm_Totale <- dfm_trim(Dfm_Totale,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
# Check
apply(textstat_summary(Corpus_Totale)[,2:11], 2, sum)
# Check
summary(Dfm_Totale)
# ANALISI ----
# Suddivisione dataset per social
Tweet_ita <- Ita_StoresReview[Ita_StoresReview$social == "twitter",]
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
# Controllo testi vuoti
apply(Tweet_ita, 2, function(x) sum(is.na(x)))
apply(Places_ita, 2, function(x) sum(is.na(x)))
Places_ita <- Places_ita[is.na(Places_ita$text) == FALSE,]
apply(Places_ita, 2, function(x) sum(is.na(x))) # 458 testi NA!!
#Campionamento per il TRAINING STAGE
Tweet_Corpus <- corpus(Tweet_ita)
names(Tweet_Corpus) <- Tweet_ita$ID
Places_Corpus <- corpus(Places_ita)
names(Places_Corpus) <- Places_ita$ID
set.seed(001)
Training_places <- sample(Places_Corpus, size = 160, replace = FALSE)
set.seed(002)
Training_tweet <- sample(Tweet_Corpus, size = 40, replace = FALSE)
print(Training_places)
Campione <- c(Training_tweet, Training_places)
Review_test <- Corpus_Totale[!(Corpus_Totale %in% Campione)]
setequal(Corpus_Totale, union(Review_test, Campione))
Corpus_Totale
# Dataset
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Aggiunta Primary key
StoresReview$ID <- seq(1:nrow(StoresReview))
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# Corpus con i testi NON vuoti
Corpus_Totale <- corpus(na.omit(Ita_StoresReview$text))
names(Corpus_Totale) <- Ita_StoresReview$ID
names(Corpus_Totale) <- Ita_StoresReview$ID[!NA]
names(Review_test)
View(Ita_StoresReview)
names(Corpus_Totale) <- Ita_StoresReview$ID[is.na(Ita_StoresReview$text) == FALSE]
names(Corpus_Totale)
str(Corpus_Totale)
# NON PULISCE TUTTO. !!, emoji
Dfm_Totale <- dfm(tokens(Corpus_Totale,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING
Dfm_Totale <- dfm_trim(Dfm_Totale,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
# ANALISI ----
# Suddivisione dataset per social
Tweet_ita <- Ita_StoresReview[Ita_StoresReview$social == "twitter",]
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
Places_ita <- Places_ita[is.na(Places_ita$text) == FALSE,] # 0 testi NA.
# Corpus per i Tweet
Tweet_Corpus <- corpus(Tweet_ita)
# Foreign key impostate
names(Tweet_Corpus) <- Tweet_ita$ID
# Dataset
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Aggiunta Primary key
StoresReview$ID <- seq(1:nrow(StoresReview))
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# Corpus con i testi NON vuoti
Corpus_Totale <- corpus(na.omit(Ita_StoresReview$text))
names(Corpus_Totale) <- Ita_StoresReview$ID[is.na(Ita_StoresReview$text) == FALSE]
# NON PULISCE TUTTO. !!, emoji
Dfm_Totale <- dfm(tokens(Corpus_Totale,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING
Dfm_Totale <- dfm_trim(Dfm_Totale,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
# ANALISI ----
# Suddivisione dataset per social
Tweet_ita <- Ita_StoresReview[Ita_StoresReview$social == "twitter",]
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
Places_ita <- Places_ita[is.na(Places_ita$text) == FALSE,] # 0 testi NA.
# Corpus per i Tweet
Tweet_Corpus <- corpus(Tweet_ita)
# Foreign key impostate
#names(Tweet_Corpus) <- Tweet_ita$ID
# Corpus per i Places
Places_Corpus <- corpus(Places_ita)
# Foreign key impostate
#names(Places_Corpus) <- Places_ita$ID
names(Tweet_Corpus)
# Foreign key impostate
names(Tweet_Corpus) <- Tweet_ita$ID
names(Tweet_Corpus)
names(Places_Corpus)
# Foreign key impostate
names(Places_Corpus) <- Places_ita$ID
names(Places_Corpus)
View(Ita_StoresReview)
View(Ita_StoresReview)
names(Places_Corpus)
set.seed(001)
Training_places <- sample(Places_Corpus, size = 160, replace = FALSE)
set.seed(002)
Training_tweet <- sample(Tweet_Corpus, size = 40, replace = FALSE)
# TRAINING DATA
Campione <- c(Training_tweet, Training_places)
# Corpus per il TEST SET
Review_test <- Corpus_Totale[!(Corpus_Totale %in% Campione)]
#Co
setequal(Corpus_Totale, union(Review_test, Campione))
names(Campione)
names(Review_test)
# TRAINING DATA
Training_data <- c(Training_tweet, Training_places)
# Corpus per il TEST SET
Review_test <- Corpus_Totale[!(Corpus_Totale %in% Training_data)]
Campione <- data.frame(
ID <- names(Training_data),
Persona <- rep(c("William","Davide","Maddalena","Giacomo"),each = 50),
Testo <- Training_data
)
View(Campione)
colnames(Campione) <- c(ID, Persona, Testo)
Campione <- data.frame(
ID <- names(Training_data),
Persona <- rep(c("William","Davide","Maddalena","Giacomo"),each = 50),
Testo <- Training_data,
Sentiment <- NA
)
View(Campione)
write_xlsx(Campione, "Lavoro.xlsx")
View(Ita_StoresReview)
Campione <- read_excel("Lavoro.xlsx")
View(Campione)
apply(Campione$Sentiment....NA, 2, function(x) sum(is.na(x)))
apply(Campione, 2, function(x) sum(is.na(x)))
Campione$Sentiment....NA[160] <- 1
apply(Campione, 2, function(x) sum(is.na(x)))
Dfm_Training <- dfm(tokens(Training_data,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Dfm_Test <- dfm(tokens(Review_test,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Campione_Corpus <- corpus(Campione)
Campione_Corpus <- corpus(Campione)
View(Ita_StoresReview)
colnames(Campione) <- c("ID", "Persona", "text","Sentiment")
View(Campione)
Campione_Corpus <- corpus(Campione)
Dfm_Training <- dfm(tokens(Campione_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Dfm_Training
Dfm_Test
Review_test_1 <- data.frame(
ID <- names(Review_test),
Review_test
)
View(Review_test_1)
Review_test_1 <- corpus(Review_test_1)
colnames(Review_test_1) <- c("ID", "text")
Review_test_1 <- corpus(Review_test_1)
Dfm_Test <- dfm(tokens(Review_test_1,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
setequal(featnames(Dfm_Training),
featnames(Dfm_Test))
View(Dfm_Training)
summary(Dfm_Training)
summary(Dfm_Test)
length(Dfm_Training@Dimnames$features)
length(Dfm_Test@Dimnames$features)
Dfm_Training <- dfm_trim(Dfm_Totale,
min_termfreq = 10,
min_docfreq = 2)
Dfm_Test <- dfm_trim(Dfm_Totale,
min_termfreq = 10,
min_docfreq = 2)
length(Dfm_Training@Dimnames$features)
length(Dfm_Test@Dimnames$features)
setequal(featnames(Dfm_Training),
featnames(Dfm_Test))
length(Dfm_Training@Dimnames$features)
length(Dfm_Test@Dimnames$features)
Prova <- dfm_match(Dfm_Test,
features = featnames(Dfm_Training))
length(Prova@Dimnames$features)
# Dataset
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Aggiunta Primary key
StoresReview$ID <- seq(1:nrow(StoresReview))
View(StoresReview)
View(StoresReview)
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
View(Ita_StoresReview)
# Corpus con i testi NON vuoti
Corpus_Totale <- corpus(na.omit(Ita_StoresReview$text))
Corpus_Totale
names(Corpus_Totale) <- Ita_StoresReview$ID[is.na(Ita_StoresReview$text) == FALSE]
Corpus_Totale
# Frequenze delle caratteristiche del Corpus
apply(textstat_summary(Corpus_Totale)[,2:11], 2, sum)
# NON PULISCE TUTTO. !!, emoji
Dfm_Totale <- dfm(tokens(Corpus_Totale,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING
Dfm_Totale <- dfm_trim(Dfm_Totale,
min_termfreq = 10,
min_docfreq = 2)
# Lunghezza del DFM
summary(Dfm_Totale)
# Top parole del DFM
topfeatures(Dfm_Totale,100)
View(Ita_StoresReview)
# ANALISI ----
# Suddivisione dataset per social
Tweet_ita <- Ita_StoresReview[Ita_StoresReview$social == "twitter",]
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
# Controllo testi vuoti
apply(Tweet_ita, 2, function(x) sum(is.na(x))) # 0 testi NA
apply(Places_ita, 2, function(x) sum(is.na(x))) # 458 testi NA!!
Places_ita <- Places_ita[is.na(Places_ita$text) == FALSE,] # 0 testi NA.
apply(Places_ita, 2, function(x) sum(is.na(x))) # 458 testi NA!!
# Corpus per i Tweet
Tweet_Corpus <- corpus(Tweet_ita)
Tweet_Corpus
# Foreign key impostate
names(Tweet_Corpus) <- Tweet_ita$ID
Tweet_Corpus
# Corpus per i Places
Places_Corpus <- corpus(Places_ita)
# Foreign key impostate
names(Places_Corpus) <- Places_ita$ID
# Campionamento con numerositÃ  200
set.seed(001)
Training_places <- sample(Places_Corpus, size = 160, replace = FALSE)
set.seed(002)
Training_tweet <- sample(Tweet_Corpus, size = 40, replace = FALSE)
# TRAINING DATA
Training_data <- c(Training_tweet, Training_places)
Training_data
# Verifica complementare
setequal(Corpus_Totale, union(Review_test, Campione))
# Corpus per il TEST SET
Review_test <- Corpus_Totale[!(Corpus_Totale %in% Training_data)]
# Verifica complementare
setequal(Corpus_Totale, union(Review_test, Campione))
# Verifica complementare
setequal(Corpus_Totale, union(Review_test, Training_data))
# Dataset del Campione
Campione <- data.frame(
ID <- names(Training_data),
Persona <- rep(c("William","Davide","Maddalena","Giacomo"),each = 50),
Testo <- Training_data,
Sentiment <- NA
)
View(Campione)
#Esportare il Campione
# write_xlsx(Campione, "Lavoro.xlsx") # NON RUNNARE !!!!!!!!!!!!!!!!!!!!!!!
Campione <- read_excel("Lavoro.xlsx")
View(Campione)
# Nome text per il text_field
apply(Campione, 2, function(x) sum(is.na(x)))
#Esportare il Campione
# write_xlsx(Campione, "Lavoro.xlsx") # NON RUNNARE !!!!!!!!!!!!!!!!!!!!!!!
Campione <- read_excel("Lavoro.xlsx")
# Nome text per il text_field
apply(Campione, 2, function(x) sum(is.na(x)))
#Esportare il Campione
# write_xlsx(Campione, "Lavoro.xlsx") # NON RUNNARE !!!!!!!!!!!!!!!!!!!!!!!
Campione <- read_excel("Lavoro.xlsx")
# Nome text per il text_field
apply(Campione, 2, function(x) sum(is.na(x)))
# Nome text per il text_field
colnames(Campione) <- c("ID", "Persona", "text","Sentiment")
Campione_Corpus <- corpus(Campione)
Dfm_Training <- dfm(tokens(Campione_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Review_test_1 <- data.frame(
ID <- names(Review_test),
Review_test
)
colnames(Review_test_1) <- c("ID", "text")
Review_test_1 <- corpus(Review_test_1)
Dfm_Test <- dfm(tokens(Review_test_1,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
length(Dfm_Training@Dimnames$features)
length(Dfm_Test@Dimnames$features)
setequal(featnames(Dfm_Training),
featnames(Dfm_Test))
Dfm_Training <- dfm_trim(Dfm_Totale,
min_termfreq = 10,
min_docfreq = 2)
Dfm_Test <- dfm_trim(Dfm_Totale,
min_termfreq = 10,
min_docfreq = 2)
length(Dfm_Training@Dimnames$features)
length(Dfm_Test@Dimnames$features)
setequal(featnames(Dfm_Training),
featnames(Dfm_Test))
Dfm_Test <- dfm_match(Dfm_Test,
features = featnames(Dfm_Training))
Matrice_Training <- as.matrix(Dfm_Training)
Matrice_Test <- as.matrix(Dfm_Test)
str(Dfm_Training@docvars$sentiment)
Dfm_Training <- dfm(tokens(Campione_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Dfm_Test <- dfm(tokens(Review_test_1,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Dfm_Training <- dfm_trim(Dfm_Training,
min_termfreq = 10,
min_docfreq = 2)
Dfm_Test <- dfm_trim(Dfm_Test,
min_termfreq = 10,
min_docfreq = 2)
length(Dfm_Training@Dimnames$features)
length(Dfm_Test@Dimnames$features)
Dfm_Test <- dfm_match(Dfm_Test,
features = featnames(Dfm_Training))
length(Dfm_Training@Dimnames$features)
length(Dfm_Test@Dimnames$features)
Matrice_Training <- as.matrix(Dfm_Training)
Matrice_Test <- as.matrix(Dfm_Test)
str(Dfm_Training@docvars$sentiment)
Dfm_Training
Dfm_Training@docvars
str(Dfm_Training@docvars$Sentiment)
Dfm_Training@docvars$Sentiment <- as.factor(Dfm_Training@docvars$Sentiment)
Dfm_Training@docvars$Sentiment
i
Campione$Sentiment <- ifelse(Campione$Sentiment == -1, "Negativo",
ifelse(Campione$Sentiment == 0, "Neutro",
"Positivo"))
Campione$Sentiment
# Verifica celle vuote.
apply(Campione, 2, function(x) sum(is.na(x)))
Campione_Corpus <- corpus(Campione)
Review_test_1 <- corpus(Review_test_1)
Dfm_Training <- dfm(tokens(Campione_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Dfm_Test <- dfm(tokens(Review_test_1,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
length(Dfm_Training@Dimnames$features) #61
Dfm_Training <- dfm_trim(Dfm_Training,
min_termfreq = 10,
min_docfreq = 2)
Dfm_Test <- dfm_trim(Dfm_Test,
min_termfreq = 10,
min_docfreq = 2)
length(Dfm_Training@Dimnames$features) #61
length(Dfm_Test@Dimnames$features) #867
setequal(featnames(Dfm_Training),
featnames(Dfm_Test))
Dfm_Test <- dfm_match(Dfm_Test,
features = featnames(Dfm_Training))
setequal(featnames(Dfm_Training),
featnames(Dfm_Test))
Matrice_Training <- as.matrix(Dfm_Training)
Matrice_Test <- as.matrix(Dfm_Test)
str(Dfm_Training@docvars$Sentiment) #impostare le minuscole
Dfm_Training@docvars$Sentiment <- as.factor(Dfm_Training@docvars$Sentiment)
Dfm_Training@docvars$Sentiment
str(Dfm_Training@docvars$Sentiment) #impostare le minuscole
