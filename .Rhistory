# librerie e dataset ----
library(readxl)
library(quanteda)
library(quanteda.textstats)
library(ggplot2)
setwd("C:/Users/WilliamSanteramo/OneDrive - ITS Angelo Rizzoli/Documenti/UFS/07 programmazione R/PROGETTO")
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# PRE- PROCESSING DFM ----
Testo_Corpus <- corpus(na.omit(Ita_StoresReview$text))
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Testo_finito <- dfm_trim(Testo_dfm,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
set.seed(000)
Review_training <- sample(Testo_Corpus, size = 200, replace = FALSE)
Review_test <- setdiff(Testo_finito, Review_training)
rm(Review_test)
help(set)
help("set")
help.search("set")
rm(setdiff)
help.search("setdiff")
help("setdiff")
Review_test <- Testo_finito[setdiff(Testo_finito, Review_training)]
Review_test <- Testo_finito[c(setdiff(Testo_finito, Review_training))]
Review_test <- Testo_Corpus[setdiff(Testo_finito, Review_training)]
rm(Review_test)
Review_test <- Testo_Corpus[!(Testo_Corpus %in% Review_training)]
setdiff(Testo_Corpus, union(Review_test, Review_training))
setequal(Testo_Corpus, union(Review_test, Review_training))
Lavoro <- list(
William = NA,
Davide = NA,
Maddalena = NA,
Giacomo = NA
)
k = 0
k <- 0
for (i in 1:4){
Lavoro[i] <- Review_training[(k+1) : (50 * i)]
k <- 50 * i
}
Lavoro
rm(i)
rm(k)
rm(Lavoro)
Lavoro <- list(
William = rep("", 50),
Davide = rep("", 50),
Maddalena = rep("", 50),
Giacomo = rep("", 50)
)
k <- 0
Lavoro
for (i in 1:4){
Lavoro[i] <- Review_training[(k+1) : (50 * i)]
k <- 50 * i
}
Lavoro
rm(Lavoro)
rm(k)
rm(i)
Lavoro <- list(
William = rep("", 50),
Davide = rep("", 50),
Maddalena = rep("", 50),
Giacomo = rep("", 50)
)
k <- 0
for (i in 1:4){
Lavoro[[i]] <- Review_training[(k+1) : (50 * i)]
k <- 50 * i
}
Lavoro
print(Lavoro)
# librerie e dataset ----
library(readxl)
library(quanteda)
library(quanteda.textstats)
library(ggplot2)
library(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# PRE- PROCESSING DFM ----
Testo_Corpus <- corpus(na.omit(Ita_StoresReview$text))
help("dfm")
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE),
tolower = TRUE,
remove = stopwords("italian"),
stem = TRUE)
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE),
tolower = TRUE,
remove = stopwords("italian")) %>%
dfm_stem()
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE),
tolower = TRUE,
remove = stopwords("italian")) %>%
dfm_wordstem()
help("tokens")
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Testo_dfm <- dfm(tokens(Testo_Corpus),
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian")
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# DFM - VERSIONE 1
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# DFM - VERSIONE 2: risultato 32 MILIONI
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING: condizioni TEMPORANEE.
Testo_finito <- dfm_trim(Testo_dfm,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
set.seed(000)
Review_training <- sample(Testo_Corpus, size = 200, replace = FALSE)
# Corpus per il TEST SET
Review_test <- Testo_Corpus[!(Testo_Corpus %in% Review_training)]
Lavoro <- list(
William = rep("", 50),
Davide = rep("", 50),
Maddalena = rep("", 50),
Giacomo = rep("", 50)
)
k <- 0
for (i in 1:4){
Lavoro[[i]] <- Review_training[(k+1) : (50 * i)]
k <- 50 * i
}
# librerie e dataset ----
library(readxl)
library(quanteda)
library(quanteda.textstats)
library(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# Creazione del Corpus prendendo solo i testi NON vuoti
Testo_Corpus <- corpus(na.omit(Ita_StoresReview$text))
# DFM - VERSIONE 2: risultato 32 MILIONI
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING: condizioni TEMPORANEE.
Testo_finito <- dfm_trim(Testo_dfm,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
help("tokens")
# DFM - VERSIONE 2: risultato 32 MILIONI
# NON PULISCE TUTTO. !!, emoji
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE,
remove_emoji = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
help("dfm")
help("corpus")
# ANALISI ----
Tabella_descrittiva <- textstat_frequency(Testo_finito, n =500)
View(Tabella_descrittiva)
# Corpus per il TEST SET
Review_test <- Testo_Corpus[!(Testo_Corpus %in% Review_training)]
Review_training <- sample(Testo_Corpus, size = 200, replace = FALSE)
#Campionamento per il TRAINING STAGE
set.seed(000)
Review_training <- sample(Testo_Corpus, size = 200, replace = FALSE)
# Corpus per il TEST SET
Review_test <- Testo_Corpus[!(Testo_Corpus %in% Review_training)]
View(StoresReview)
