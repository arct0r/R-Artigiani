# librerie e dataset ----
library(readxl)
library(quanteda)
library(quanteda.textstats)
library(ggplot2)
setwd("C:/Users/WilliamSanteramo/OneDrive - ITS Angelo Rizzoli/Documenti/UFS/07 programmazione R/PROGETTO")
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# PRE- PROCESSING DFM ----
Testo_Corpus <- corpus(na.omit(Ita_StoresReview$text))
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Testo_finito <- dfm_trim(Testo_dfm,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
set.seed(000)
Review_training <- sample(Testo_Corpus, size = 200, replace = FALSE)
Review_test <- setdiff(Testo_finito, Review_training)
rm(Review_test)
help(set)
help("set")
help.search("set")
rm(setdiff)
help.search("setdiff")
help("setdiff")
Review_test <- Testo_finito[setdiff(Testo_finito, Review_training)]
Review_test <- Testo_finito[c(setdiff(Testo_finito, Review_training))]
Review_test <- Testo_Corpus[setdiff(Testo_finito, Review_training)]
rm(Review_test)
Review_test <- Testo_Corpus[!(Testo_Corpus %in% Review_training)]
setdiff(Testo_Corpus, union(Review_test, Review_training))
setequal(Testo_Corpus, union(Review_test, Review_training))
Lavoro <- list(
William = NA,
Davide = NA,
Maddalena = NA,
Giacomo = NA
)
k = 0
k <- 0
for (i in 1:4){
Lavoro[i] <- Review_training[(k+1) : (50 * i)]
k <- 50 * i
}
Lavoro
rm(i)
rm(k)
rm(Lavoro)
Lavoro <- list(
William = rep("", 50),
Davide = rep("", 50),
Maddalena = rep("", 50),
Giacomo = rep("", 50)
)
k <- 0
Lavoro
for (i in 1:4){
Lavoro[i] <- Review_training[(k+1) : (50 * i)]
k <- 50 * i
}
Lavoro
rm(Lavoro)
rm(k)
rm(i)
Lavoro <- list(
William = rep("", 50),
Davide = rep("", 50),
Maddalena = rep("", 50),
Giacomo = rep("", 50)
)
k <- 0
for (i in 1:4){
Lavoro[[i]] <- Review_training[(k+1) : (50 * i)]
k <- 50 * i
}
Lavoro
print(Lavoro)
# librerie e dataset ----
library(readxl)
library(quanteda)
library(quanteda.textstats)
library(ggplot2)
library(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# PRE- PROCESSING DFM ----
Testo_Corpus <- corpus(na.omit(Ita_StoresReview$text))
help("dfm")
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE),
tolower = TRUE,
remove = stopwords("italian"),
stem = TRUE)
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE),
tolower = TRUE,
remove = stopwords("italian")) %>%
dfm_stem()
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE),
tolower = TRUE,
remove = stopwords("italian")) %>%
dfm_wordstem()
help("tokens")
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Testo_dfm <- dfm(tokens(Testo_Corpus),
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian")
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# DFM - VERSIONE 1
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# DFM - VERSIONE 2: risultato 32 MILIONI
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING: condizioni TEMPORANEE.
Testo_finito <- dfm_trim(Testo_dfm,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
set.seed(000)
Review_training <- sample(Testo_Corpus, size = 200, replace = FALSE)
# Corpus per il TEST SET
Review_test <- Testo_Corpus[!(Testo_Corpus %in% Review_training)]
Lavoro <- list(
William = rep("", 50),
Davide = rep("", 50),
Maddalena = rep("", 50),
Giacomo = rep("", 50)
)
k <- 0
for (i in 1:4){
Lavoro[[i]] <- Review_training[(k+1) : (50 * i)]
k <- 50 * i
}
# librerie e dataset ----
library(readxl)
library(quanteda)
library(quanteda.textstats)
library(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# Creazione del Corpus prendendo solo i testi NON vuoti
Testo_Corpus <- corpus(na.omit(Ita_StoresReview$text))
# DFM - VERSIONE 2: risultato 32 MILIONI
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING: condizioni TEMPORANEE.
Testo_finito <- dfm_trim(Testo_dfm,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
help("tokens")
# DFM - VERSIONE 2: risultato 32 MILIONI
# NON PULISCE TUTTO. !!, emoji
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE,
remove_emoji = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
help("dfm")
help("corpus")
# ANALISI ----
Tabella_descrittiva <- textstat_frequency(Testo_finito, n =500)
View(Tabella_descrittiva)
# Corpus per il TEST SET
Review_test <- Testo_Corpus[!(Testo_Corpus %in% Review_training)]
Review_training <- sample(Testo_Corpus, size = 200, replace = FALSE)
#Campionamento per il TRAINING STAGE
set.seed(000)
Review_training <- sample(Testo_Corpus, size = 200, replace = FALSE)
# Corpus per il TEST SET
Review_test <- Testo_Corpus[!(Testo_Corpus %in% Review_training)]
View(StoresReview)
# librerie e dataset ----
library(readxl)
library(writexl)
library(rstudioapi)
library(quanteda)
library(quanteda.textstats)
setwd(dirname(getActiveDocumentContext()$path))
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# Creazione del Corpus prendendo solo i testi NON vuoti
Testo_Corpus <- corpus(na.omit(Ita_StoresReview$text))
# DFM - VERSIONE 2: risultato 32 MILIONI
# NON PULISCE TUTTO. !!, emoji
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING: condizioni TEMPORANEE.
Testo_finito <- dfm_trim(Testo_dfm,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
help("openxlsx")
help(sample)
View(Ita_StoresReview)
table(Ita_StoresReview$social)
Tweet_Stores <- Ita_StoresReview[Ita_StoresReview$social == "twitter",]
View(Tweet_Stores)
Places_Stores <- Ita_StoresReview[Ita_StoresReview$social == "places",]
help("set.seed")
set.seed(002)
Training_tweet <- sample(Tweet_Stores$text, size = 40, replace = FALSE)
set.seed(001)
Trainig_places <- sample(Places_Stores$text, size = 160, replace = FALSE)
Testo_Corpus
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
# Creazione del Corpus prendendo solo i testi NON vuoti
Testo_Corpus <- corpus(na.omit(Ita_StoresReview))
Testo_Corpus
View(Ita_StoresReview)
Tweet_ita <- Ita_StoresReview[Ita_StoresReview$social == "twitter",]
View(Tweet_ita)
View(Tweet_ita)
apply(Ita_StoresReview$social, 2, function(x) sum(is.na(x)))
apply(Ita_StoresReview, 2, function(x) sum(is.na(x)))
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
View(Places_ita)
View(StoresReview)
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
StoresReview$ID <- seq(1:nrow(StoresReview))
View(StoresReview)
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
View(Ita_StoresReview)
Tweet_ita <- Ita_StoresReview[Ita_StoresReview$social == "twitter",]
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
View(Tweet_ita)
# Creazione del Corpus prendendo solo i testi NON vuoti
Corpus_Totale <- corpus(na.omit(Ita_StoresReview))
View(StoresReview)
View(Tweet_ita)
# Creazione del Corpus prendendo solo i testi NON vuoti
Corpus_Totale <- corpus(na.omit(Ita_StoresReview$text))
# Check
apply(textstat_summary(Testo_Corpus)[,2:11], 2, sum)
# Check
apply(textstat_summary(Corpus_Totale)[,2:11], 2, sum)
# NON PULISCE TUTTO. !!, emoji
Testo_dfm <- dfm(tokens(Testo_Corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# NON PULISCE TUTTO. !!, emoji
Dfm_Totale <- dfm(tokens(Corpus_Totale,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c(stopwords("italian"))) %>%
tokens_wordstem(language = "italian"))
# Applicazione del TRIMMING: condizioni TEMPORANEE.
DFM_Totale_Finito <- dfm_trim(Dfm_Totale,
min_termfreq = 10,
#max_termfreq = 500,
min_docfreq = 2)
View(Tweet_ita)
apply(Tweet_ita, 2, function(x) sum(is.na(x)))
apply(Places_ita, 2, function(x) sum(is.na(x)))
Places_ita <- Places_ita[is.na(Places_ita$text) == TRUE,]
apply(Places_ita, 2, function(x) sum(is.na(x)))
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
Places_ita <- Places_ita[is.na(Places_ita$text) == FALSE,]
apply(Places_ita, 2, function(x) sum(is.na(x)))
set.seed(001)
Training_places <- sample(Places_ita, size = 160, replace = FALSE)
Training_tweet <- sample(Tweet_Stores$text, size = 40, replace = FALSE)
Training_tweet <- sample(Tweet_ita, size = 40, replace = FALSE)
View(Places_ita)
Training_places <- sample(Places_ita$text, size = 160, replace = FALSE)
Training_places
# librerie e dataset ----
library(readxl)
StoresReview <- read_excel("GRUPPO 3-4-5. Industry elettronica.xlsx")
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
View(Ita_StoresReview)
StoresReview$ID <- seq(1:nrow(StoresReview))
# Dataset con sole recensioni in italiano.
Ita_StoresReview <- StoresReview[StoresReview$lang_value == "it" | is.na(StoresReview$lang_value) == TRUE,]
Tweet_ita <- Ita_StoresReview[Ita_StoresReview$social == "twitter",]
Places_ita <- Ita_StoresReview[Ita_StoresReview$social == "places",]
apply(Tweet_ita, 2, function(x) sum(is.na(x)))
apply(Places_ita, 2, function(x) sum(is.na(x)))
Places_ita <- Places_ita[is.na(Places_ita$text) == FALSE,]
Prova <- corpus(Tweet_ita)
dimnames(Prova)
names(Prova)
View(Tweet_ita)
names(Prova) <- Tweet_ita$ID
names(Prova)
Prova
rm(Prova)
#Campionamento per il TRAINING STAGE
Tweet_Corpus <- corpus(Tweet_ita)
names(Tweet_Corpus) <- Tweet_ita$ID
Places_Corpus <- corpus(Places_ita)
names(Places_Corpus) <- Places_ita$ID
